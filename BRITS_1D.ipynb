{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd8AbLqV4Evw",
        "outputId": "b38099aa-1b1e-4b59-aa37-80dbe00d3c08"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3JWOuVv4L6o",
        "outputId": "50cbf628-9bc3-4c40-c695-a4379ef8dc6a"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle -q\n",
        "!pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "9XWRpvQm4qPY",
        "outputId": "ee600990-d6a3-4b92-c457-bd5bc00df054"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmuv3uC54rLn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu2AV-Ob4wVI",
        "outputId": "84c16456-0dad-4c45-f9fe-0e1dc9a0f3dd"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c brist1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaYhnuJM4zYA",
        "outputId": "0c42326d-b7e6-4d10-88e6-1311b9bf04bc"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./data/brist-1d\n",
        "!unzip brist1d.zip -d ./data/brist-1d\n",
        "!ls ./data/brist-1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-B0MVl1h3HT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDDUeTK_4LiZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "import shutil\n",
        "\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option(\"display.max_rows\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "1V7mXRq441JQ",
        "outputId": "c10f56d0-afd2-4a23-83a2-93ebd5bbd0b8"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/data/brist-1d/train.csv')\n",
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GacgfBl_5Maw"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "\n",
        "    TARGET_COL = 'bg+1+00'\n",
        "    GROUP_COL = 'p_num'\n",
        "    N_SPLITS = 5\n",
        "    # SEED_LIST = [2,12,22,32,42,52,62,72,82,92,102,112,122,132,142,152]\n",
        "    SEED_LIST = [42]\n",
        "\n",
        "    ERR = 1e-5\n",
        "\n",
        "    BG_LOW = 3.9\n",
        "    BG_HIGH = 10.0\n",
        "\n",
        "\n",
        "    TRAIN_CATBOOST = False\n",
        "    TRAIN_XGB = True\n",
        "    TRAIN_LGB = False\n",
        "\n",
        "    early_stop = 200\n",
        "\n",
        "    catboost_params = {\n",
        "        # 'random_state': 42,  # This will be updated per seed\n",
        "        'loss_function': 'RMSE',\n",
        "        'eval_metric': 'RMSE',\n",
        "        'learning_rate': 0.025,\n",
        "        'iterations': 1000,\n",
        "        'task_type': 'CPU',\n",
        "        'depth': 7,\n",
        "    }\n",
        "\n",
        "    xgboost_params = {\n",
        "        'random_state': 42,  # This will be updated per seed\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'learning_rate': 0.025,\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cpu',\n",
        "        'max_depth': 7,\n",
        "    }\n",
        "\n",
        "\n",
        "    lgb_params = {\n",
        "        # 'random_state': 42,  # This will be updated per seed\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'boosting': 'gbdt',\n",
        "        'num_threads': 8,\n",
        "        'learning_rate': 0.025,\n",
        "        # 'n_estimators': 20000,\n",
        "        'device': 'cpu',\n",
        "        'max_depth': 5,\n",
        "        'num_leaves': 64,\n",
        "        # 'min_data_in_leaf': 50,\n",
        "        # 'lambda_l1': 30,\n",
        "        # 'lambda_l2': 10,\n",
        "        'verbosity': -1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmHpwNMKoe34"
      },
      "outputs": [],
      "source": [
        "def _extract_time(col: str) -> float:\n",
        "    time_str = col.split('-')[-1] if '-' in col else col\n",
        "    hours, minutes = map(int, time_str.split('+'))\n",
        "    return hours + minutes/60\n",
        "\n",
        "def _within_window(col: str, window: str) -> bool:\n",
        "    try:\n",
        "        col_time = _extract_time(col)\n",
        "        window_time = _extract_time(window)\n",
        "        return col_time <= window_time\n",
        "    except:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A8rakMxWb9Q"
      },
      "outputs": [],
      "source": [
        "# @title feature engineering\n",
        "\n",
        "def calculate_patient_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    bg_columns = [col for col in df.columns if col.startswith('bg-')]\n",
        "    insulin_columns = [col for col in df.columns if col.startswith('insulin-')]\n",
        "    hr_columns = [col for col in df.columns if col.startswith('hr-')]\n",
        "    steps_columns = [col for col in df.columns if col.startswith('steps-')]\n",
        "    cals_columns = [col for col in df.columns if col.startswith('cals-')]\n",
        "\n",
        "\n",
        "    df['bg_sum_5hr'] = df[bg_columns].sum(axis=1)\n",
        "    df['bg_mean_5hr'] = df['bg_sum_5hr'] / len(bg_columns)\n",
        "\n",
        "    df['insulin_sum_5hr'] = df[insulin_columns].sum(axis=1)\n",
        "    df['insulin_mean_5hr'] = df['insulin_sum_5hr'] / len(insulin_columns)\n",
        "\n",
        "    df['hr_sum_5hr'] = df[hr_columns].sum(axis=1)\n",
        "    df['hr_mean_5hr'] = df['hr_sum_5hr'] / len(hr_columns)\n",
        "\n",
        "    df['steps_sum_5hr'] = df[steps_columns].sum(axis=1)\n",
        "    df['steps_mean_5hr'] = df['steps_sum_5hr'] / len(steps_columns)\n",
        "\n",
        "    df['cals_sum_5hr'] = df[cals_columns].sum(axis=1)\n",
        "    df['cals_mean_5hr'] = df['cals_sum_5hr'] / len(cals_columns)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sx43tuQjsR0"
      },
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "\n",
        "  df.columns = df.columns.str.replace(':', '+', regex=False)\n",
        "\n",
        "  df['time'] = pd.to_datetime(df['time'])\n",
        "  df['hour'] = df['time'].dt.hour\n",
        "  df['minute'] = df['time'].dt.minute\n",
        "\n",
        "  df['part_of_day'] = pd.cut(df['hour'],\n",
        "                                 bins=[-np.inf, 6, 12, 18, np.inf],\n",
        "                                 labels=['night', 'morning', 'afternoon', 'evening'])\n",
        "\n",
        "  df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
        "  df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
        "\n",
        "  cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "  numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "  df[cat_cols] = df[cat_cols].fillna('Unknown').astype('category')\n",
        "  df[numeric_cols] = df[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "  df = calculate_patient_features(df)\n",
        "\n",
        "  df.drop(df.filter(regex='carbs|activity').columns, axis=1, inplace=True)\n",
        "\n",
        "  df.drop(['time'], axis=1, inplace=True)\n",
        "  df.drop(['id'], axis=1, inplace=True)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_4_tRil5OTA",
        "outputId": "b264ffd2-eb0d-46b0-ede4-a1af40661e1a"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "osR5HiJm5Plw",
        "outputId": "fc9775ea-0004-4af2-d93e-4a5def34d07c"
      },
      "outputs": [],
      "source": [
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Hb3czN1mlRdF",
        "outputId": "aef19904-6488-4246-c60d-45879846df60"
      },
      "outputs": [],
      "source": [
        "train['p_num'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MgbeCoy4k66j"
      },
      "outputs": [],
      "source": [
        "# @title train_catboost\n",
        "def train_catboost(data, model_save_dir='catboost_models'):\n",
        "\n",
        "    if os.path.exists(model_save_dir):\n",
        "        shutil.rmtree(model_save_dir)\n",
        "\n",
        "    # Create the directory\n",
        "    os.makedirs(model_save_dir)\n",
        "\n",
        "    X = data.drop([CONFIG.TARGET_COL, CONFIG.GROUP_COL], axis=1)\n",
        "    y = data[CONFIG.TARGET_COL]\n",
        "    groups = data[CONFIG.GROUP_COL]\n",
        "\n",
        "    cv = GroupKFold(n_splits=CONFIG.N_SPLITS)\n",
        "    all_oof_preds = np.zeros(X.shape[0])\n",
        "    all_metrics = []\n",
        "    all_models = []\n",
        "    feature_importances = np.zeros(X.shape[1])\n",
        "\n",
        "    seed_oof_preds = []\n",
        "\n",
        "    cat_features = [X.columns.get_loc(col) for col in X.select_dtypes(include=['category'])]\n",
        "\n",
        "    for seed in CONFIG.SEED_LIST:\n",
        "        print(f'Training with seed: {seed} for feature importance calculation...')\n",
        "        CONFIG.catboost_params['random_state'] = seed\n",
        "\n",
        "        oof_preds = np.zeros(X.shape[0])\n",
        "        metrics = []\n",
        "        models = []\n",
        "\n",
        "        for fi, (train_idx, valid_idx) in enumerate(cv.split(X, y, groups)):\n",
        "\n",
        "            print(f'Fold {fi + 1}/{CONFIG.N_SPLITS} with seed {seed}...')\n",
        "\n",
        "            model = cb.CatBoostRegressor(**CONFIG.catboost_params)\n",
        "\n",
        "            model.fit(X.iloc[train_idx], y.iloc[train_idx],\n",
        "                      eval_set=(X.iloc[valid_idx], y.iloc[valid_idx]),\n",
        "                      use_best_model=True,\n",
        "                      # early_stopping_rounds=Config.early_stop,\n",
        "                      cat_features=cat_features,\n",
        "                      verbose=200)\n",
        "\n",
        "            preds = model.predict(X.iloc[valid_idx])\n",
        "            oof_preds[valid_idx] = preds\n",
        "\n",
        "            rmse = sqrt(mean_squared_error(y.iloc[valid_idx], preds))\n",
        "            metrics.append(rmse)\n",
        "            print(f'Fold {fi + 1} RMSE: {rmse:.4f}')\n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "            model_save_path = os.path.join(model_save_dir, f'catboost_model_seed_{seed}_fold_{fi}.pkl')\n",
        "            joblib.dump(model, model_save_path)\n",
        "\n",
        "            feature_importances += model.get_feature_importance()\n",
        "\n",
        "        seed_oof_preds.append(oof_preds)\n",
        "        all_models.append(models)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "    oof_preds_avg = np.mean(seed_oof_preds, axis=0)\n",
        "    oof_rmse = sqrt(mean_squared_error(y, oof_preds_avg))\n",
        "\n",
        "    all_fold_rmses = np.array([rmse for metrics in all_metrics for rmse in metrics])\n",
        "\n",
        "    print(f'Average RMSE across seeds: {np.mean([np.mean(m) for m in all_metrics]):.4f}')\n",
        "    print(f'STD of RMSE across folds: {np.std(all_fold_rmses):.4f}')\n",
        "    print(f'OOF RMSE across seeds: {oof_rmse:.4f}')\n",
        "\n",
        "        # t-statistic and p-value calculation\n",
        "    seed_fold_rmses = np.array([[rmse for rmse in metrics] for metrics in all_metrics])\n",
        "\n",
        "    for i in range(len(CONFIG.SEED_LIST)):\n",
        "        for j in range(i + 1, len(CONFIG.SEED_LIST)):\n",
        "            t_stat, p_value = stats.ttest_rel(seed_fold_rmses[i], seed_fold_rmses[j])\n",
        "            print(f'T-statistic between seed {CONFIG.SEED_LIST[i]} and {CONFIG.SEED_LIST[j]}: {t_stat:.4f}, p-value: {p_value:.4f}')\n",
        "\n",
        "    return all_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUaXKE1Ru9_5"
      },
      "outputs": [],
      "source": [
        "# @title train_xgboost\n",
        "def train_xgboost(data):\n",
        "\n",
        "    X = data.drop([CONFIG.TARGET_COL, CONFIG.GROUP_COL], axis=1)\n",
        "    y = data[CONFIG.TARGET_COL]\n",
        "    groups = data[CONFIG.GROUP_COL]\n",
        "\n",
        "    cv = GroupKFold(n_splits=CONFIG.N_SPLITS)\n",
        "    all_oof_preds = np.zeros(X.shape[0])\n",
        "    all_metrics = []\n",
        "    all_models = []\n",
        "    feature_importances = np.zeros(X.shape[1])\n",
        "\n",
        "    seed_oof_preds = []\n",
        "\n",
        "    cat_cols = X.select_dtypes(include='category').columns\n",
        "\n",
        "    for seed in CONFIG.SEED_LIST:\n",
        "        print(f'Training with seed: {seed} for feature importance calculation...')\n",
        "        # CONFIG.xgboost_params['random_state'] = seed\n",
        "\n",
        "        oof_preds = np.zeros(X.shape[0])\n",
        "        metrics = []\n",
        "        models = []\n",
        "\n",
        "        for fi, (train_idx, valid_idx) in enumerate(cv.split(X, y, groups)):\n",
        "\n",
        "            # if fi != 0:\n",
        "            #     continue\n",
        "\n",
        "            print(f'Fold {fi + 1}/{CONFIG.N_SPLITS} with seed {seed}...')\n",
        "\n",
        "            dtrain = xgb.DMatrix(X.iloc[train_idx], label=y.iloc[train_idx], enable_categorical=True)\n",
        "            dvalid = xgb.DMatrix(X.iloc[valid_idx], label=y.iloc[valid_idx], enable_categorical=True)\n",
        "\n",
        "            model = xgb.train(\n",
        "                params=CONFIG.xgboost_params,\n",
        "                dtrain=dtrain,\n",
        "                num_boost_round=1000,\n",
        "                evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
        "                verbose_eval=200,\n",
        "                early_stopping_rounds=CONFIG.early_stop,\n",
        "            )\n",
        "\n",
        "            preds = model.predict(xgb.DMatrix(X.iloc[valid_idx], enable_categorical=True))\n",
        "            oof_preds[valid_idx] = preds\n",
        "\n",
        "            rmse = sqrt(mean_squared_error(y.iloc[valid_idx], preds))\n",
        "            metrics.append(rmse)\n",
        "            print(f'Fold {fi + 1} RMSE: {rmse:.4f}')\n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "        seed_oof_preds.append(oof_preds)\n",
        "        all_models.append(models)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "    oof_preds_avg = np.mean(seed_oof_preds, axis=0)\n",
        "    oof_rmse = sqrt(mean_squared_error(y, oof_preds_avg))\n",
        "\n",
        "    all_fold_rmses = np.array([rmse for metrics in all_metrics for rmse in metrics])\n",
        "\n",
        "    print(f'Average RMSE across seeds: {np.mean([np.mean(m) for m in all_metrics]):.4f}')\n",
        "    print(f'STD of RMSE across folds: {np.std(all_fold_rmses):.4f}')\n",
        "    print(f'OOF RMSE across seeds: {oof_rmse:.4f}')\n",
        "\n",
        "    return all_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74Kc9emld86R"
      },
      "outputs": [],
      "source": [
        "# @title train_lgb\n",
        "def train_lgb(data):\n",
        "    X = data.drop([CONFIG.TARGET_COL, CONFIG.GROUP_COL], axis=1)\n",
        "    y = data[CONFIG.TARGET_COL]\n",
        "    groups = data[CONFIG.GROUP_COL]\n",
        "\n",
        "    cv = GroupKFold(n_splits=CONFIG.N_SPLITS)\n",
        "    all_oof_preds = np.zeros(X.shape[0])\n",
        "    all_metrics = []\n",
        "    all_models = []\n",
        "\n",
        "    seed_oof_preds = []\n",
        "\n",
        "    for seed in CONFIG.SEED_LIST:\n",
        "        print(f'Training with seed: {seed} for feature importance calculation...')\n",
        "\n",
        "        oof_preds = np.zeros(X.shape[0])\n",
        "        metrics = []\n",
        "        models = []\n",
        "\n",
        "        for fi, (train_idx, valid_idx) in enumerate(cv.split(X, y, groups)):\n",
        "\n",
        "            print(f'Fold {fi + 1}/{CONFIG.N_SPLITS} with seed {seed}...')\n",
        "            dtrain = lgb.Dataset(X.iloc[train_idx], label=y.iloc[train_idx])\n",
        "            dvalid = lgb.Dataset(X.iloc[valid_idx], label=y.iloc[valid_idx], reference=dtrain)\n",
        "\n",
        "            model = lgb.train(\n",
        "                params={**CONFIG.lgb_params, 'random_state': seed},\n",
        "                train_set=dtrain,\n",
        "                valid_sets=[dtrain, dvalid],\n",
        "                num_boost_round=1000,\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=CONFIG.early_stop), lgb.log_evaluation(period=200)]\n",
        "            )\n",
        "\n",
        "\n",
        "            preds = model.predict(X.iloc[valid_idx])\n",
        "            oof_preds[valid_idx] = preds\n",
        "\n",
        "            rmse = sqrt(mean_squared_error(y.iloc[valid_idx], preds))\n",
        "            metrics.append(rmse)\n",
        "            print(f'Fold {fi + 1} RMSE: {rmse:.4f}')\n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "        seed_oof_preds.append(oof_preds)\n",
        "        all_models.append(models)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "    oof_preds_avg = np.mean(seed_oof_preds, axis=0)\n",
        "    oof_rmse = sqrt(mean_squared_error(y, oof_preds_avg))\n",
        "\n",
        "    all_fold_rmses = np.array([rmse for metrics in all_metrics for rmse in metrics])\n",
        "\n",
        "    print(f'Average RMSE across seeds: {np.mean([np.mean(m) for m in all_metrics]):.4f}')\n",
        "    print(f'STD of RMSE across folds: {np.std(all_fold_rmses):.4f}')\n",
        "    print(f'OOF RMSE across seeds: {oof_rmse:.4f}')\n",
        "\n",
        "\n",
        "    seed_fold_rmses = np.array([[rmse for rmse in metrics] for metrics in all_metrics])\n",
        "\n",
        "    for i in range(len(CONFIG.SEED_LIST)):\n",
        "        for j in range(i + 1, len(CONFIG.SEED_LIST)):\n",
        "            t_stat, p_value = stats.ttest_rel(seed_fold_rmses[i], seed_fold_rmses[j])\n",
        "            print(f'T-statistic between seed {CONFIG.SEED_LIST[i]} and {CONFIG.SEED_LIST[j]}: {t_stat:.4f}, p-value: {p_value:.4f}')\n",
        "\n",
        "    return all_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp82Bc5_oc-b",
        "outputId": "e86835af-0c99-4a6f-a5a5-1713368aebf3"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train = preprocess(train)\n",
        "\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "AQ0XyEfRARCT",
        "outputId": "5c3f43b5-7304-4385-c89b-8b975b0a07f8"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "ChSTXfVmoiGC",
        "outputId": "0a71ca25-aa69-4111-c8f7-00754a45b903"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if CONFIG.TRAIN_CATBOOST:\n",
        "    catboost_models = train_catboost(train)\n",
        "\n",
        "if CONFIG.TRAIN_XGB:\n",
        "    xgboost_models = train_xgboost(train)\n",
        "\n",
        "\n",
        "if CONFIG.TRAIN_LGB:\n",
        "    lgb_models = train_lgb(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtO5UVbZ0OI5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#lgbm 2.06\n",
        "# std: 0.144\n",
        "\n",
        "# xgboost\n",
        "# STD of RMSE across folds: 0.1352\n",
        "# OOF RMSE across seeds: 2.0997"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "YrLNbmAA5Q_Q",
        "outputId": "c5fc0ab6-2ac8-4c90-80ce-d27782ca5065"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('/content/data/brist-1d/test.csv')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZivxH1dA8Yv0"
      },
      "outputs": [],
      "source": [
        "def infer_xgboost(test_data, all_models):\n",
        "\n",
        "    X_test = test_data.drop(CONFIG.GROUP_COL, axis=1)\n",
        "    cat_cols = X_test.select_dtypes(include='category').columns\n",
        "\n",
        "    all_test_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "    for seed_models in all_models:\n",
        "        seed_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "        for model in seed_models:\n",
        "            dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
        "            fold_preds = model.predict(dtest)\n",
        "            seed_preds += fold_preds / len(seed_models)  \n",
        "\n",
        "        all_test_preds += seed_preds / len(all_models)  \n",
        "\n",
        "    return all_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWrfe44Tszcn"
      },
      "outputs": [],
      "source": [
        "def infer_catboost(test_data, all_models):\n",
        "\n",
        "    X_test = test_data.drop(CONFIG.GROUP_COL, axis=1)\n",
        "    cat_cols = X_test.select_dtypes(include='category').columns\n",
        "\n",
        "    all_test_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "    for seed_models in all_models:\n",
        "        seed_preds = np.zeros(X_test.shape[0])\n",
        "        for model in seed_models:\n",
        "            fold_preds = model.predict(X_test)\n",
        "            seed_preds += fold_preds / len(seed_models)  \n",
        "        all_test_preds += seed_preds / len(all_models)  \n",
        "\n",
        "    return all_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GeHS3Gps78v"
      },
      "outputs": [],
      "source": [
        "def infer_lightgbm(test_data, all_models):\n",
        "\n",
        "    X_test = test_data.drop(CONFIG.GROUP_COL, axis=1)\n",
        "    cat_cols = X_test.select_dtypes(include='category').columns\n",
        "\n",
        "    all_test_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "    for seed_models in all_models:\n",
        "        seed_preds = np.zeros(X_test.shape[0])\n",
        "        for model in seed_models:\n",
        "            fold_preds = model.predict(X_test)\n",
        "            seed_preds += fold_preds / len(seed_models)  \n",
        "        all_test_preds += seed_preds / len(all_models)  \n",
        "    return all_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR4VUNDsl_Gs",
        "outputId": "318d2154-1089-4da5-dc6a-c9aec6f4af6a"
      },
      "outputs": [],
      "source": [
        "test = preprocess(test)\n",
        "\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "yTexlGu8wXJx",
        "outputId": "ec67bad0-8376-4ce1-80a9-19febaea7351"
      },
      "outputs": [],
      "source": [
        "xgb_predictions = infer_xgboost(test, xgboost_models)\n",
        "cb_predictions = infer_catboost(test, catboost_models)\n",
        "lgb_predictions = infer_lightgbm(test, lgb_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfs8Kumv5oQn"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/content/data/brist-1d/sample_submission.csv')\n",
        "sub['bg+1:00'] = xgb_predictions\n",
        "sub.to_csv('xgb_submission.csv', index=False)\n",
        "print(sub.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50fNeSNCtO6I"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/content/data/brist-1d/sample_submission.csv')\n",
        "sub['bg+1:00'] = cb_predictions\n",
        "sub.to_csv('cb_submission.csv', index=False)\n",
        "print(sub.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbngsT9CtPTy"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/content/data/brist-1d/sample_submission.csv')\n",
        "sub['bg+1:00'] = lgb_predictions\n",
        "sub.to_csv('lgb_submission.csv', index=False)\n",
        "print(sub.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x_c3JEn5sAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
